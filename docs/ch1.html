<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 Summarizing data | Statistical Methods in Water Resources with R</title>
  <meta name="description" content="This project aims to translate Helsel and Hirsch ‘Statistical Methods in Water Resources’ into R." />
  <meta name="generator" content="bookdown 0.16 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 Summarizing data | Statistical Methods in Water Resources with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This project aims to translate Helsel and Hirsch ‘Statistical Methods in Water Resources’ into R." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Summarizing data | Statistical Methods in Water Resources with R" />
  
  <meta name="twitter:description" content="This project aims to translate Helsel and Hirsch ‘Statistical Methods in Water Resources’ into R." />
  

<meta name="author" content="MiRoVaGo" />


<meta name="date" content="2020-01-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="ch2.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical Methods in Water Resources with R</a></li>    

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="ch1.html"><a href="ch1.html"><i class="fa fa-check"></i><b>1</b> Summarizing data</a><ul>
<li class="chapter" data-level="1.1" data-path="ch1.html"><a href="ch1.html#characteristics-of-water-resources-data"><i class="fa fa-check"></i><b>1.1</b> Characteristics of Water Resources Data</a></li>
<li class="chapter" data-level="1.2" data-path="ch1.html"><a href="ch1.html#measures-of-location"><i class="fa fa-check"></i><b>1.2</b> Measures of Location</a><ul>
<li class="chapter" data-level="1.2.1" data-path="ch1.html"><a href="ch1.html#classical-measure-the-mean"><i class="fa fa-check"></i><b>1.2.1</b> Classical Measure – the Mean</a></li>
<li class="chapter" data-level="1.2.2" data-path="ch1.html"><a href="ch1.html#resistant-measure-the-median"><i class="fa fa-check"></i><b>1.2.2</b> Resistant Measure – the Median</a></li>
<li class="chapter" data-level="1.2.3" data-path="ch1.html"><a href="ch1.html#other-measures-of-location"><i class="fa fa-check"></i><b>1.2.3</b> Other Measures of Location</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="ch1.html"><a href="ch1.html#measures-of-spread"><i class="fa fa-check"></i><b>1.3</b> Measures of Spread</a><ul>
<li class="chapter" data-level="1.3.1" data-path="ch1.html"><a href="ch1.html#classical-measures"><i class="fa fa-check"></i><b>1.3.1</b> Classical Measures</a></li>
<li class="chapter" data-level="1.3.2" data-path="ch1.html"><a href="ch1.html#resistant-measures"><i class="fa fa-check"></i><b>1.3.2</b> Resistant Measures</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="ch1.html"><a href="ch1.html#measures-of-skewness"><i class="fa fa-check"></i><b>1.4</b> Measures of Skewness</a><ul>
<li class="chapter" data-level="1.4.1" data-path="ch1.html"><a href="ch1.html#classical-measure-of-skewness"><i class="fa fa-check"></i><b>1.4.1</b> Classical Measure of Skewness</a></li>
<li class="chapter" data-level="1.4.2" data-path="ch1.html"><a href="ch1.html#resistant-measure-of-skewness"><i class="fa fa-check"></i><b>1.4.2</b> Resistant Measure of Skewness</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="ch1.html"><a href="ch1.html#other-resistant-measures"><i class="fa fa-check"></i><b>1.5</b> Other Resistant Measures</a></li>
<li class="chapter" data-level="1.6" data-path="ch1.html"><a href="ch1.html#outliers"><i class="fa fa-check"></i><b>1.6</b> Outliers</a></li>
<li class="chapter" data-level="1.7" data-path="ch1.html"><a href="ch1.html#transformations"><i class="fa fa-check"></i><b>1.7</b> Transformations</a><ul>
<li class="chapter" data-level="1.7.1" data-path="ch1.html"><a href="ch1.html#the-ladder-of-powers"><i class="fa fa-check"></i><b>1.7.1</b> The Ladder of Powers</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch1.html"><a href="ch1.html#exercises"><i class="fa fa-check"></i>Exercises</a><ul>
<li class="chapter" data-level="" data-path="ch1.html"><a href="ch1.html#section"><i class="fa fa-check"></i>1.1</a></li>
<li class="chapter" data-level="" data-path="ch1.html"><a href="ch1.html#section-1"><i class="fa fa-check"></i>1.2</a></li>
<li class="chapter" data-level="" data-path="ch1.html"><a href="ch1.html#section-2"><i class="fa fa-check"></i>1.3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="ch2.html"><a href="ch2.html"><i class="fa fa-check"></i><b>2</b> Graphical Data Analysis</a><ul>
<li class="chapter" data-level="2.1" data-path="ch2.html"><a href="ch2.html#ch2-1"><i class="fa fa-check"></i><b>2.1</b> Graphical Analysis of Single Data Sets</a><ul>
<li class="chapter" data-level="2.1.1" data-path="ch2.html"><a href="ch2.html#histograms"><i class="fa fa-check"></i><b>2.1.1</b> Histograms</a></li>
<li class="chapter" data-level="2.1.2" data-path="ch2.html"><a href="ch2.html#stem-and-leaf-diagrams"><i class="fa fa-check"></i><b>2.1.2</b> Stem and Leaf Diagrams</a></li>
<li class="chapter" data-level="2.1.3" data-path="ch2.html"><a href="ch2.html#quantile-plots"><i class="fa fa-check"></i><b>2.1.3</b> Quantile Plots</a></li>
<li class="chapter" data-level="2.1.4" data-path="ch2.html"><a href="ch2.html#boxplots"><i class="fa fa-check"></i><b>2.1.4</b> Boxplots</a></li>
<li class="chapter" data-level="2.1.5" data-path="ch2.html"><a href="ch2.html#probability-plots"><i class="fa fa-check"></i><b>2.1.5</b> Probability Plots</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="ch2.html"><a href="ch2.html#ch2-2"><i class="fa fa-check"></i><b>2.2</b> Graphical Comparisons of Two or More Data Sets</a><ul>
<li class="chapter" data-level="2.2.1" data-path="ch2.html"><a href="ch2.html#histograms-1"><i class="fa fa-check"></i><b>2.2.1</b> Histograms</a></li>
<li class="chapter" data-level="2.2.2" data-path="ch2.html"><a href="ch2.html#dot-and-line-plots-of-means-standard-deviations"><i class="fa fa-check"></i><b>2.2.2</b> Dot and Line Plots of Means, Standard Deviations</a></li>
<li class="chapter" data-level="2.2.3" data-path="ch2.html"><a href="ch2.html#boxplots-1"><i class="fa fa-check"></i><b>2.2.3</b> Boxplots</a></li>
<li class="chapter" data-level="2.2.4" data-path="ch2.html"><a href="ch2.html#probability-plots-1"><i class="fa fa-check"></i><b>2.2.4</b> Probability Plots</a></li>
<li class="chapter" data-level="2.2.5" data-path="ch2.html"><a href="ch2.html#q-q-plots"><i class="fa fa-check"></i><b>2.2.5</b> Q-Q Plots</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="ch2.html"><a href="ch2.html#scatterplots-and-enhancements"><i class="fa fa-check"></i><b>2.3</b> Scatterplots and Enhancements</a><ul>
<li class="chapter" data-level="2.3.1" data-path="ch2.html"><a href="ch2.html#evaluating-linearity"><i class="fa fa-check"></i><b>2.3.1</b> Evaluating Linearity</a></li>
<li class="chapter" data-level="2.3.2" data-path="ch2.html"><a href="ch2.html#evaluating-differences-in-location-on-a-scatterplot"><i class="fa fa-check"></i><b>2.3.2</b> Evaluating Differences in Location on a Scatterplot</a></li>
<li class="chapter" data-level="2.3.3" data-path="ch2.html"><a href="ch2.html#evaluating-differences-in-spread"><i class="fa fa-check"></i><b>2.3.3</b> Evaluating Differences in Spread</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="ch2.html"><a href="ch2.html#graphs-for-multivariate-data"><i class="fa fa-check"></i><b>2.4</b> Graphs for Multivariate Data</a><ul>
<li class="chapter" data-level="2.4.1" data-path="ch2.html"><a href="ch2.html#profile-plots"><i class="fa fa-check"></i><b>2.4.1</b> Profile Plots</a></li>
<li class="chapter" data-level="2.4.2" data-path="ch2.html"><a href="ch2.html#star-plots"><i class="fa fa-check"></i><b>2.4.2</b> Star Plots</a></li>
<li class="chapter" data-level="2.4.3" data-path="ch2.html"><a href="ch2.html#trilinear-diagrams"><i class="fa fa-check"></i><b>2.4.3</b> Trilinear Diagrams</a></li>
<li class="chapter" data-level="2.4.4" data-path="ch2.html"><a href="ch2.html#plots-of-principal-components"><i class="fa fa-check"></i><b>2.4.4</b> Plots of Principal Components</a></li>
<li class="chapter" data-level="2.4.5" data-path="ch2.html"><a href="ch2.html#other-multivariate-plots"><i class="fa fa-check"></i><b>2.4.5</b> Other Multivariate Plots</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch2.html"><a href="ch2.html#exercises-1"><i class="fa fa-check"></i>Exercises</a><ul>
<li class="chapter" data-level="" data-path="ch2.html"><a href="ch2.html#section-3"><i class="fa fa-check"></i>2.1</a></li>
<li class="chapter" data-level="" data-path="ch2.html"><a href="ch2.html#section-4"><i class="fa fa-check"></i>2.2</a></li>
<li class="chapter" data-level="" data-path="ch2.html"><a href="ch2.html#section-5"><i class="fa fa-check"></i>2.3</a></li>
<li class="chapter" data-level="" data-path="ch2.html"><a href="ch2.html#section-6"><i class="fa fa-check"></i>2.4</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ch3.html"><a href="ch3.html"><i class="fa fa-check"></i><b>3</b> Describing Uncertainty</a><ul>
<li class="chapter" data-level="3.1" data-path="ch3.html"><a href="ch3.html#definition-of-interval-estimates"><i class="fa fa-check"></i><b>3.1</b> Definition of Interval Estimates</a></li>
<li class="chapter" data-level="3.2" data-path="ch3.html"><a href="ch3.html#interpretation-of-interval-estimates"><i class="fa fa-check"></i><b>3.2</b> Interpretation of Interval Estimates</a></li>
<li class="chapter" data-level="3.3" data-path="ch3.html"><a href="ch3.html#ch3-3"><i class="fa fa-check"></i><b>3.3</b> Confidence Intervals for the Median</a><ul>
<li class="chapter" data-level="3.3.1" data-path="ch3.html"><a href="ch3.html#ch3-3-1"><i class="fa fa-check"></i><b>3.3.1</b> Nonparametric Interval Estimate For The Median</a></li>
<li class="chapter" data-level="3.3.2" data-path="ch3.html"><a href="ch3.html#ch3-3-2"><i class="fa fa-check"></i><b>3.3.2</b> Parametric Interval Estimate For The Median</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="ch3.html"><a href="ch3.html#ch3-4"><i class="fa fa-check"></i><b>3.4</b> Confidence Intervals For The Mean</a><ul>
<li class="chapter" data-level="3.4.1" data-path="ch3.html"><a href="ch3.html#ch3-4-1"><i class="fa fa-check"></i><b>3.4.1</b> Symmetric Confidence Interval For The Mean</a></li>
<li class="chapter" data-level="3.4.2" data-path="ch3.html"><a href="ch3.html#ch3-4-2"><i class="fa fa-check"></i><b>3.4.2</b> Asymmetric Confidence Interval For The Mean (For Skewed Data)</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="ch3.html"><a href="ch3.html#ch3-5"><i class="fa fa-check"></i><b>3.5</b> Nonparametric Prediction Intervals</a><ul>
<li class="chapter" data-level="3.5.1" data-path="ch3.html"><a href="ch3.html#two-sided-nonparametric-prediction-interval"><i class="fa fa-check"></i><b>3.5.1</b> Two-Sided Nonparametric Prediction Interval</a></li>
<li class="chapter" data-level="3.5.2" data-path="ch3.html"><a href="ch3.html#one-sided-nonparametric-prediction-interval"><i class="fa fa-check"></i><b>3.5.2</b> One-Sided Nonparametric Prediction Interval</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="ch3.html"><a href="ch3.html#ch3-6"><i class="fa fa-check"></i><b>3.6</b> Parametric Prediction Intervals</a><ul>
<li class="chapter" data-level="3.6.1" data-path="ch3.html"><a href="ch3.html#symmetric-prediction-interval"><i class="fa fa-check"></i><b>3.6.1</b> Symmetric Prediction Interval</a></li>
<li class="chapter" data-level="3.6.2" data-path="ch3.html"><a href="ch3.html#asymmetric-prediction-intervals"><i class="fa fa-check"></i><b>3.6.2</b> Asymmetric Prediction Intervals</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="ch3.html"><a href="ch3.html#ch3-7"><i class="fa fa-check"></i><b>3.7</b> Confidence Intervals For Percentiles (Tolerance Intervals)</a><ul>
<li class="chapter" data-level="3.7.1" data-path="ch3.html"><a href="ch3.html#ch3-7-1"><i class="fa fa-check"></i><b>3.7.1</b> Nonparametric Confidence Intervals For Percentiles</a></li>
<li class="chapter" data-level="3.7.2" data-path="ch3.html"><a href="ch3.html#ch3-7-2"><i class="fa fa-check"></i><b>3.7.2</b> Nonparametric Tests For Percentiles</a></li>
<li class="chapter" data-level="3.7.3" data-path="ch3.html"><a href="ch3.html#ch3-7-3"><i class="fa fa-check"></i><b>3.7.3</b> Parametric Confidence Intervals For Percentiles</a></li>
<li class="chapter" data-level="3.7.4" data-path="ch3.html"><a href="ch3.html#ch3-7-4"><i class="fa fa-check"></i><b>3.7.4</b> Parametric Tests For Percentiles</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="ch3.html"><a href="ch3.html#other-uses-for-confidence-intervals"><i class="fa fa-check"></i><b>3.8</b> Other Uses For Confidence Intervals</a><ul>
<li class="chapter" data-level="3.8.1" data-path="ch3.html"><a href="ch3.html#implications-of-non-normality-for-detection-of-outliers"><i class="fa fa-check"></i><b>3.8.1</b> Implications of Non-Normality For Detection of Outliers</a></li>
<li class="chapter" data-level="3.8.2" data-path="ch3.html"><a href="ch3.html#implications-of-non-normality-for-quality-control"><i class="fa fa-check"></i><b>3.8.2</b> Implications of Non-Normality For Quality Control</a></li>
<li class="chapter" data-level="3.8.3" data-path="ch3.html"><a href="ch3.html#implications-of-non-normality-for-sampling-design"><i class="fa fa-check"></i><b>3.8.3</b> Implications of Non-Normality For Sampling Design</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch3.html"><a href="ch3.html#exercises-2"><i class="fa fa-check"></i>Exercises</a><ul>
<li class="chapter" data-level="" data-path="ch3.html"><a href="ch3.html#section-7"><i class="fa fa-check"></i>3.1</a></li>
<li class="chapter" data-level="" data-path="ch3.html"><a href="ch3.html#section-8"><i class="fa fa-check"></i>3.2</a></li>
<li class="chapter" data-level="" data-path="ch3.html"><a href="ch3.html#section-9"><i class="fa fa-check"></i>3.3</a></li>
<li class="chapter" data-level="" data-path="ch3.html"><a href="ch3.html#section-10"><i class="fa fa-check"></i>3.4</a></li>
<li class="chapter" data-level="" data-path="ch3.html"><a href="ch3.html#section-11"><i class="fa fa-check"></i>3.5</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><em>Statistical Methods in Water Resources</em> with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ch1" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Summarizing data</h1>
<p>When determining how to appropriately analyze any collection of data, the first consideration must be the characteristics of the data themselves. Little is gained by employing analysis procedures which assume that the data possess characteristics which in fact they do not. The result of such false assumptions may be that the interpretations provided by the analysis are incorrect, or unnecessarily inconclusive. Therefore we begin this book with a discussion of the common characteristics of water resources data. These characteristics will determine the selection of appropriate data analysis procedures.</p>
<p>One of the most frequent tasks when analyzing data is to describe and summarize those data in forms which convey their important characteristics. “What is the sulfate concentration one might expect in rainfall at this location”? “How variable is hydraulic conductivity”? “What is the 100 year flood” (the 99th percentile of annual flood maxima)? Estimation of these and similar summary statistics are basic to understanding data. Characteristics often described include: a measure of the center of the data, a measure of spread or variability, a measure of the symmetry of the data distribution, and perhaps estimates of extremes such as some large or small percentile. This chapter discusses methods for summarizing or describing data.</p>
<p>This first chapter also quickly demonstrates one of the major themes of the book – the use of robust and resistant techniques. The reasons why one might prefer to use a resistant measure, such as the median, over a more classical measure such as the mean, are explained.</p>
<p>The data about which a statement or summary is to be made are called the <strong>population</strong>, or sometimes the <strong>target population</strong>. These might be concentrations in all waters of an aquifer or stream reach, or all streamflows over some time at a particular site. Rarely are all such data available to the scientist. It may be physically impossible to collect all data of interest (all the water in a stream over the study period), or it may just be financially impossible to collect them. Instead, a subset of the data called the <strong>sample</strong> is selected and measured in such a way that conclusions about the sample may be extended to the entire population. Statistics computed from the sample are only inferences or estimates about characteristics of the population, such as location, spread, and skewness. Measures of location are usually the sample mean and sample median. Measures of spread include the sample standard deviation and sample interquartile range. Use of the term “sample” before each statistic explicitly demonstrates that these only estimate the population value, the population mean or median, etc. As sample estimates are far more common than measures based on the entire population, the term “mean” should be interpreted as the “sample mean”, and similarly for other statistics used in this book. When population values are discussed they will be explicitly stated as such.</p>
<div id="characteristics-of-water-resources-data" class="section level2">
<h2><span class="header-section-number">1.1</span> Characteristics of Water Resources Data</h2>
<p>Data analyzed by the water resources scientist often have the following characteristics:</p>
<ol style="list-style-type: decimal">
<li>A lower bound of zero. No negative values are possible.</li>
<li>Presence of ‘outliers’, observations considerably higher or lower than most of the data, which infrequently but regularly occur. outliers on the high side are more common in water
resources.</li>
<li>Positive skewness, due to items 1 and 2. An example of a skewed distribution, the lognormal distribution, is presented in figure <a href="ch1.html#fig:fig-1-1">1.1</a>. Values of an observation on the horizontal axis are plotted against the frequency with which that value occurs. These density functions are like histograms of large data sets whose bars become infinitely narrow. Skewness can be expected when outlying values occur in only one direction.</li>
<li>Non-normal distribution of data, due to items 1 - 3 above. Figure <a href="ch1.html#fig:fig-1-2">1.2</a> shows an important symmetric distribution, the normal. While many statistical tests assume data follow a normal distribution as in figure <a href="ch1.html#fig:fig-1-2">1.2</a>, water resources data often look more like figure <a href="ch1.html#fig:fig-1-1">1.1</a>. In addition, symmetry does not guarantee normality. Symmetric data with more observations at both extremes (heavy tails) than occurs for a normal distribution are also non-normal.</li>
<li>Data reported only as below or above some threshold (censored data). Examples include concentrations below one or more detection limits, annual flood stages known only to be lower than a level which would have caused a public record of the flood, and hydraulic heads known only to be above the land surface (artesian wells on old maps).</li>
<li>Seasonal patterns. Values tend to be higher or lower in certain seasons of the year.</li>
<li>Autocorrelation. Consecutive observations tend to be strongly correlated with each other. For the most common kind of autocorrelation in water resources (positive autocorrelation), high values tend to follow high values and low values tend to follow low values.</li>
<li>Dependence on other uncontrolled variables. Values strongly covary with water discharge, hydraulic conductivity, sediment grain size, or some other variable.</li>
</ol>
<p>Methods for analysis of water resources data, whether the simple summarization methods such
as those in this chapter, or the more complex procedures of later chapters, should recognize
these common characteristics.</p>
</div>
<div id="measures-of-location" class="section level2">
<h2><span class="header-section-number">1.2</span> Measures of Location</h2>
<p>The mean and median are the two most commonly-used measures of location, though they are
not the only measures available. What are the properties of these two measures, and when
should one be employed over the other?</p>
<div id="classical-measure-the-mean" class="section level3">
<h3><span class="header-section-number">1.2.1</span> Classical Measure – the Mean</h3>
<p>The mean (<span class="math inline">\(\mathbf{\overline{X}}\)</span>) is computed as the sum of all data values <strong>X</strong><sub>i</sub>, divided by the sample size n:
<span class="math display" id="eq:1-1">\[\begin{equation}
\overline{X} = \sum_{i=1}^{n} \frac{X_{i}}{n}
\tag{1.1}
\end{equation}\]</span></p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1">mean_x &lt;-<span class="st"> </span><span class="kw">mean</span>(x)</a></code></pre></div>
For data which are in one of k groups, equation <a href="ch1.html#eq:1-1">(1.1)</a> can be rewritten to show that the overall
mean depends on the mean for each group, weighted by the number of observations n<sub>i</sub> in each
group:
<span class="math display" id="eq:1-2">\[\begin{equation}
\overline{X} = \sum_{i=1}^{n} \overline{X}_{i} \frac{n_{i}}{n}
\tag{1.2}
\end{equation}\]</span>
where <span class="math inline">\(\mathbf{\overline{X}_{i}}\)</span> is the mean for group i. The influence of any one observation X<sub>j</sub> on the mean can be seen by placing all but that one observation in one “group”, or
<span class="math display" id="eq:1-3">\[\begin{equation}
\begin{split}
\overline{X} &amp; =\overline{X}_{(j)} \frac{n-1}{n} + X_{j} \bullet \frac{1}{n} \\
&amp; =\overline{X}_{(j)} + \left( X_{j} - \overline{X}_{(j)} \right) \bullet \frac{1}{n}
\end{split}
\tag{1.3}
\end{equation}\]</span>
where <span class="math inline">\(\mathbf{\overline{X}_{(j)}}\)</span> is the mean of all observations excluding X<sub>j</sub>. Each observation’s influence on the overall mean <span class="math inline">\(\mathbf{\overline{X}}\)</span> is <span class="math inline">\(\left( \mathbf{X_{j} -\overline{X}_{(j)}} \right)\)</span>, the distance between the observation and the mean excluding that observation. Thus all observations do not have the same influence on the mean. An ‘outlier’ observation, either high or low, has a much greater influence on the overall mean <span class="math inline">\(\mathbf{\overline{X}}\)</span> than does a more ‘typical’ observation, one closer to its <span class="math inline">\(\mathbf{\overline{X}_{(j)}}\)</span>.
<div class="figure" style="text-align: center"><span id="fig:fig-1-1"></span>
<img src="figures/1_1.png" alt="Density Function for a Lognormal Distribution" width="221" />
<p class="caption">
Figure 1.1: Density Function for a Lognormal Distribution
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:fig-1-2"></span>
<img src="figures/1_2.png" alt="Density Function for a Normal Distribution" width="218" />
<p class="caption">
Figure 1.2: Density Function for a Normal Distribution
</p>
</div>
<p>Another way of illustrating this influence is to realize that the mean is the balance point of the data, when each point is stacked on a number line (figure <a href="ch1.html#fig:fig-1-3-1">1.3</a>). Data points further from the center exert a stronger downward force than those closer to the center. If one point near the center were removed, the balance point would only need a small adjustment to keep the data set in balance. But if one outlying value were removed, the balance point would shift dramatically (figure <a href="ch1.html#fig:fig-1-3-2">1.4</a>). This sensitivity to the magnitudes of a small number of points in the data set defines why the mean is not a “resistant” measure of location. It is not resistant to changes in the presence of, or to changes in the magnitudes of, a few outlying observations.</p>
When this strong influence of a few observations is desirable, the mean is an appropriate measure of center. This usually occurs when computing units of mass, such as the average concentration of sediment from several samples in a cross-section. Suppose that sediment
concentrations closer to the river banks were much higher than those in the center. Waters represented by a bottle of high concentration would exert more influence (due to greater mass of sediment per volume) on the final concentration than waters of low or average concentration. This is entirely appropriate, as the same would occur if the stream itself were somehow mechanically mixed throughout its cross section.
<div class="figure" style="text-align: center"><span id="fig:fig-1-3-1"></span>
<img src="figures/1_3_a.png" alt="The mean (triangle) as balance point of a data set" width="266" />
<p class="caption">
Figure 1.3: The mean (triangle) as balance point of a data set
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:fig-1-3-2"></span>
<img src="figures/1_3_b.png" alt="Shift of the mean downward after removal of outlier" width="261" />
<p class="caption">
Figure 1.4: Shift of the mean downward after removal of outlier
</p>
</div>
</div>
<div id="resistant-measure-the-median" class="section level3">
<h3><span class="header-section-number">1.2.2</span> Resistant Measure – the Median</h3>
<p>The median, or 50th percentile P<sub>0.50</sub>, is the central value of the distribution when the data are ranked in order of magnitude. For an odd number of observations, the median is the data point which has an equal number of observations both above and below it. For an even number of observations, it is the average of the two central observations. To compute the median, first rank the observations from smallest to largest, so that x<sub>1</sub> is the smallest observation, up to x<sub>n</sub>, the largest observation. Then
<span class="math display" id="eq:1-4">\[\begin{equation}
\begin{aligned}
median \left(P_{0.50} \right) &amp; = X_{(n+1)/2} &amp;&amp; \text{when n is odd, and}\\
median \left(P_{0.50} \right) &amp; = \frac{1}{2} \left( X_{(n/2)} +  X_{(n/2) + 1} \right) &amp;&amp; \text{when n is even}
\end{aligned}
\tag{1.4}
\end{equation}\]</span></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1">median_x &lt;-<span class="st"> </span><span class="kw">median</span>(x)</a></code></pre></div>
<p>The median is only minimally affected by the magnitude of a single observation, being determined solely by the relative order of observations. This resistance to the effect of a change in value or presence of outlying observations is often a desirable property. To demonstrate the resistance of the median, suppose the last value of the following data set (a) of 7 observations were multiplied by 10 to obtain data set (b):</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1">a &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">9</span>,<span class="dv">11</span>,<span class="dv">11</span>,<span class="dv">12</span>)</a>
<a class="sourceLine" id="cb3-2" data-line-number="2"><span class="kw">mean</span>(a)</a></code></pre></div>
<pre><code>## [1] 8.142857</code></pre>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="kw">median</span>(a)</a></code></pre></div>
<pre><code>## [1] 9</code></pre>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1">b &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">9</span>,<span class="dv">11</span>,<span class="dv">11</span>,<span class="dv">120</span>)</a>
<a class="sourceLine" id="cb7-2" data-line-number="2"><span class="kw">mean</span>(b)</a></code></pre></div>
<pre><code>## [1] 23.57143</code></pre>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1"><span class="kw">median</span>(b)</a></code></pre></div>
<pre><code>## [1] 9</code></pre>
<p>The mean increases from 8.1 to 23.6. The median, the <span class="math inline">\(\frac{(7+1)}{2}\)</span>th or 4th lowest data point, is unaffected by the change.</p>
<p>When a summary value is desired that is not strongly influenced by a few extreme observations, the median is preferable to the mean. One such example is the chemical concentration one might expect to find over many streams in a given region. Using the median, one stream with unusually high concentration has no greater effect on the estimate than one with low concentration. The mean concentration may be pulled towards the outlier, and be higher than concentrations found in most of the streams. Not so for the median.</p>
</div>
<div id="other-measures-of-location" class="section level3">
<h3><span class="header-section-number">1.2.3</span> Other Measures of Location</h3>
<p>Three other measures of location are less frequently used: the mode, the geometric mean, and the trimmed mean. The mode is the most frequently observed value. It is the value having the highest bar in a histogram. It is far more applicable for grouped data, data which are recorded only as falling into a finite number of categories, than for continuous data. It is very easy to obtain, but a poor measure of location for continuous data, as its value often depends on the arbitrary grouping of those data.</p>
<p>The geometric mean (GM) is often reported for positively skewed data sets. It is the mean of the logarithms, transformed back to their original units.
<span class="math display" id="eq:1-5">\[\begin{equation}
\begin{aligned}
GM &amp; = exp\left( \overline{Y} \right), &amp;&amp; \text{where $Y_{i} = \ln{(X_{i})}$}\\
\end{aligned}
\tag{1.5}
\end{equation}\]</span></p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1">geometric_mean_x &lt;-<span class="st"> </span><span class="kw">geoMean</span>(x)</a></code></pre></div>
<p>(in this book the natural, base e logarithm will be abbreviated <strong>ln</strong>, and its inverse e<sup>x</sup> abbreviated <strong>exp(x)</strong>). For positively skewed data the geometric mean is usually quite close to the median. In fact, when the logarithms of the data are symmetric, the geometric mean is an unbiased estimate of the median. This is because the median and mean logarithms are equal, as in figure <a href="ch1.html#fig:fig-1-2">1.2</a>. When transformed back to original units, the geometric mean continues to be an estimate for the median, but is not an estimate for the mean (figure <a href="ch1.html#fig:fig-1-1">1.1</a>).</p>
Compromises between the median and mean are available by trimming off several of the lowest and highest observations, and calculating the mean of what is left. Such estimates of location are not influenced by the most extreme (and perhaps anomalous) ends of the sample, as is the mean. Yet they allow the magnitudes of most of the values to affect the estimate, unlike the median. These estimators are called “trimmed means”, and any desirable percentage of the data may be trimmed away. The most common trimming is to remove 25 percent of the data on each end – the resulting mean of the central 50 percent of data is commonly called the “trimmed mean”, but is more precisely the 25 percent trimmed mean. A “0% trimmed mean” is the sample mean itself, while trimming all but 1 or 2 central values produces the median. Percentages of trimming should be explicitly stated when used. The trimmed mean is a resistant estimator of location, as it is not strongly influenced by outliers, and works well for a wide variety of distributional shapes (normal, lognormal, etc.). It may be considered a weighted mean, where data beyond the cutoff ‘window’ are given a weight of 0, and those within the window a weight of 1.0 (see figure <a href="ch1.html#fig:fig-1-4">1.5</a>).
<div class="figure" style="text-align: center"><span id="fig:fig-1-4"></span>
<img src="figures/1_4.png" alt="Window diagram for the trimmed mean" width="279" />
<p class="caption">
Figure 1.5: Window diagram for the trimmed mean
</p>
</div>
</div>
</div>
<div id="measures-of-spread" class="section level2">
<h2><span class="header-section-number">1.3</span> Measures of Spread</h2>
<p>It is just as important to know how variable the data are as it is to know their general center or location. Variability is quantified by measures of spread.</p>
<div id="classical-measures" class="section level3">
<h3><span class="header-section-number">1.3.1</span> Classical Measures</h3>
<p>The sample variance, and its square root the sample standard deviation, are the classical measures of spread. Like the mean, they are strongly influenced by outlying values.
<span class="math display" id="eq:1-6">\[\begin{equation}
\begin{aligned}
s^{2} &amp; = \sum_{i=1}^{n} \frac{(X_{i} - \overline{X})^{2}}{(n-1)} &amp;&amp; \text{sample variance}\\
\end{aligned}
\tag{1.6}
\end{equation}\]</span></p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1">variance_x &lt;-<span class="st"> </span><span class="kw">var</span>(x)</a></code></pre></div>
<p><span class="math display" id="eq:1-7">\[\begin{equation}
\begin{aligned}
s &amp; = \sqrt{s^{2}} &amp;&amp; \text{sample standard deviation}
\end{aligned}
\tag{1.7}
\end{equation}\]</span></p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" data-line-number="1">standard_deviation_x &lt;-<span class="st"> </span><span class="kw">sd</span>(x)</a></code></pre></div>
<p>They are computed using the squares of deviations of data from the mean, so that outliers influence their magnitudes even more so than for the mean. When outliers are present these measures are unstable and inflated. They may give the impression of much greater spread than is indicated by the majority of the data set.</p>
</div>
<div id="resistant-measures" class="section level3">
<h3><span class="header-section-number">1.3.2</span> Resistant Measures</h3>
<p>The interquartile range (IQR) is the most commonly-used resistant measure of spread. It measures the range of the central 50 percent of the data, and is not influenced at all by the 25 percent on either end. It is therefore the width of the non-zero weight window for the trimmed mean of figure <a href="ch1.html#fig:fig-1-4">1.5</a>.</p>
<p>The IQR is defined as the 75th percentile minus the 25th percentile. The 75th, 50th (median) and 25th percentiles split the data into four equal-sized quarters. The 75th percentile (P<sub>.75</sub>), also called the upper quartile, is a value which exceeds no more than 75 percent of the data <u>and</u> is exceeded by no more than 25 percent of the data. The 25th percentile (P<sub>.25</sub>) or lower quartile is a value which exceeds no more than 25 percent of the data <u>and</u> is exceeded by no more than 75 percent. Consider a data set ordered from smallest to largest: X<sub>i</sub>, i = 1,…n. Percentiles (P<sub>j</sub>) are computed using equation <a href="ch1.html#eq:1-8">(1.8)</a>
<span class="math display" id="eq:1-8">\[\begin{equation}
\begin{aligned}
&amp; P_{j} = X_{(n + 1) \bullet j} \\
\text{where } &amp; \text{n is the sample size of $X_{i}$, and} \\
&amp; \text{j is the fraction of data less than or equal to the percentile value (for the 25th, 50th}\\
&amp; \text{and 75th percentiles, j = .25, .50, and .75).}
\end {aligned}
\tag{1.8}
\end{equation}\]</span></p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1">interquartile_range_x &lt;-<span class="st"> </span><span class="kw">IQR</span>(x, <span class="dt">type =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb14-2" data-line-number="2"><span class="co"># There are 9 different types you can specify. Type 2 seems to be the method used herein.</span></a></code></pre></div>
<p>Non-integer values of (n+1)•j imply linear interpolation between adjacent values of X. For the example 1 data set given earlier, n = 7, and therefore the 25th percentile is X<sub>(7+1)•.25</sub> or X<sub>2</sub> = 4, the second lowest observation. The 75th percentile is X<sub>6</sub>, the 6th lowest observation, or 11. The IQR is therefore 11 − 4 = 7.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" data-line-number="1">a</a></code></pre></div>
<pre><code>## [1]  2  4  8  9 11 11 12</code></pre>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" data-line-number="1"><span class="kw">IQR</span>(a, <span class="dt">type =</span> <span class="dv">2</span>)</a></code></pre></div>
<pre><code>## [1] 7</code></pre>
<p>One resistant estimator of spread other than the IQR is the Median Absolute Deviation, or MAD. The MAD is computed by first listing the absolute value of all differences |d| between each observation and the median. The median of these absolute values is then the MAD.
<span class="math display" id="eq:1-9">\[\begin{equation}
\begin{aligned}
&amp; MAD (X_{i}) = median |d_{i}|, &amp;&amp; \text{where $d_{i} = X_{i} - median(X_{i})$}
\end {aligned}
\tag{1.9}
\end{equation}\]</span></p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" data-line-number="1">median_absolute_deviation_x &lt;-<span class="st"> </span><span class="kw">mad</span>(x, <span class="dt">constant =</span> <span class="dv">1</span>)</a></code></pre></div>
<p>Comparison of each estimate of spread for the Example 1 data set is as follows. When the last value is changed from 12 to 120, the standard deviation increases from 3.8 to 42.7. The IQR and the MAD remain exactly the same.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" data-line-number="1"><span class="kw">c</span>(<span class="kw">IQR</span>(a, <span class="dt">type =</span> <span class="dv">2</span>), <span class="kw">var</span>(a), <span class="kw">mad</span>(a, <span class="dt">constant =</span> <span class="dv">1</span>))</a></code></pre></div>
<pre><code>## [1]  7.00000 14.47619  2.00000</code></pre>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb22-1" data-line-number="1"><span class="kw">c</span>(<span class="kw">IQR</span>(b, <span class="dt">type =</span> <span class="dv">2</span>), <span class="kw">var</span>(b), <span class="kw">mad</span>(b, <span class="dt">constant =</span> <span class="dv">1</span>))</a></code></pre></div>
<pre><code>## [1]    7.000 1819.619    2.000</code></pre>
</div>
</div>
<div id="measures-of-skewness" class="section level2">
<h2><span class="header-section-number">1.4</span> Measures of Skewness</h2>
<p>Hydrologic data are typically skewed, meaning that data sets are not symmetric around the mean or median, with extreme values extending out longer in one direction. The density function for a lognormal distribution shown previously as figure <a href="ch1.html#fig:fig-1-1">1.1</a> illustrates this skewness. When extreme values extend the right tail of the distribution, as they do with figure <a href="ch1.html#fig:fig-1-1">1.1</a>, the data are said to be skewed to the right, or positively skewed. Left skewness, when the tail extends to the left, is called negative skew.</p>
<p>When data are skewed the mean is not expected to equal the median, but is pulled toward the tail of the distribution. Thus for positive skewness the mean exceeds more than 50 percent of the data, as in figure <a href="ch1.html#fig:fig-1-1">1.1</a>. The standard deviation is also inflated by data in the tail. Therefore, tables of summary statistics which include only the mean and standard deviation or variance are of questionable value for water resources data, as those data often have positive skewness. The mean and standard deviation reported may not describe the majority of the data very well. Both will be inflated by outlying observations. Summary tables which include the median and other percentiles have far greater applicability to skewed data. Skewed data also call into question the applicability of hypothesis tests which are based on assumptions that the data have a normal distribution. These tests, called parametric tests, may be of questionable value when applied to water resources data, as the data are often neither normal nor even symmetric. Later chapters will discuss this in much detail, and suggest several solutions.</p>
<div id="classical-measure-of-skewness" class="section level3">
<h3><span class="header-section-number">1.4.1</span> Classical Measure of Skewness</h3>
<p>The coefficient of skewness (g) is the skewness measure used most often. It is the adjusted third moment divided by the cube of the standard deviation:
<span class="math display" id="eq:1-10">\[\begin{equation}
g = \frac{n}{(n-1)(n-2)} \sum_{i = 1}^{n} \frac{(x_{i} - \overline{X})^{3}}{s^{3}}
\tag{1.10}
\end{equation}\]</span></p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb24-1" data-line-number="1"><span class="kw">library</span>(e1071)</a>
<a class="sourceLine" id="cb24-2" data-line-number="2">skewness_x &lt;-<span class="st"> </span><span class="kw">skewness</span>(x, <span class="dt">type =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb24-3" data-line-number="3"><span class="co"># There are 3 different types you can specify. Type 2 seems to be the method used herein.</span></a></code></pre></div>
<p>A right-skewed distribution has positive g; a left-skewed distribution has negative g. Again, the influence of a few outliers is important – an otherwise symmetric distribution having one outlier will produce a large (and possibly misleading) measure of skewness. For the example 1 data, the g skewness coefficient increases from −0.8 to 2.6 when the last data point is changed from 12 to
120.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb25-1" data-line-number="1">e1071<span class="op">::</span><span class="kw">skewness</span>(a, <span class="dt">type =</span> <span class="dv">2</span>)</a></code></pre></div>
<pre><code>## [1] -0.8398416</code></pre>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb27-1" data-line-number="1">e1071<span class="op">::</span><span class="kw">skewness</span>(b, <span class="dt">type =</span> <span class="dv">2</span>)</a></code></pre></div>
<pre><code>## [1] 2.610094</code></pre>
</div>
<div id="resistant-measure-of-skewness" class="section level3">
<h3><span class="header-section-number">1.4.2</span> Resistant Measure of Skewness</h3>
<p>A more resistant measure of skewness is the quartile skew coefficient qs (<span class="citation">Kenney and Keeping (<a href="#ref-kenney_mathematics_1954">1954</a>)</span>):
<span class="math display" id="eq:1-11">\[\begin{equation}
qs = \frac{(P_{.75}-P_{.50})-(P_{.50}-P_{.25})}{P_{.75}-P_{.25}}
\tag{1.11}
\end{equation}\]</span></p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb29-1" data-line-number="1">quartiles_x &lt;-<span class="st"> </span><span class="kw">quantile</span>(x, <span class="dt">prob =</span> <span class="kw">c</span>(<span class="fl">0.25</span>, <span class="fl">0.50</span>, <span class="fl">0.75</span>), <span class="dt">type =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb29-2" data-line-number="2"><span class="co"># There are 9 different types you can specify. Type 2 seems to be the method used herein.</span></a>
<a class="sourceLine" id="cb29-3" data-line-number="3">quartile_skew_x &lt;-<span class="st"> </span>((quartiles_x[<span class="dv">3</span>] <span class="op">-</span><span class="st"> </span>quartiles_x[<span class="dv">2</span>]) <span class="op">-</span><span class="st"> </span>(quartiles_x[<span class="dv">2</span>] <span class="op">-</span><span class="st"> </span>quartiles_x[<span class="dv">1</span>])) <span class="op">/</span><span class="st"> </span>(quartiles_x[<span class="dv">3</span>] <span class="op">-</span><span class="st"> </span>quartiles_x[<span class="dv">1</span>])</a></code></pre></div>
<p>the difference in distances of the upper and lower quartiles from the median, divided by the IQR. A right-skewed distribution again has positive qs; a left-skewed distribution has negative qs. Similar to the trimmed mean and IQR, qs uses the central 50 percent of the data. For the example 1 data, qs = (11−9) − (9−4) / (11−4) = −0.43 both before and after alteration of the last data point. Note that this resistance may be a liability if sensitivity to a few observations is important.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb30-1" data-line-number="1">quartiles_a &lt;-<span class="st"> </span><span class="kw">quantile</span>(a, <span class="dt">prob =</span> <span class="kw">c</span>(<span class="fl">0.25</span>, <span class="fl">0.50</span>, <span class="fl">0.75</span>), <span class="dt">type =</span> <span class="dv">2</span>, <span class="dt">names =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb30-2" data-line-number="2">quartile_skew_a &lt;-<span class="st"> </span>((quartiles_a[<span class="dv">3</span>] <span class="op">-</span><span class="st"> </span>quartiles_a[<span class="dv">2</span>]) <span class="op">-</span><span class="st"> </span>(quartiles_a[<span class="dv">2</span>] <span class="op">-</span><span class="st"> </span>quartiles_a[<span class="dv">1</span>])) <span class="op">/</span><span class="st"> </span>(quartiles_a[<span class="dv">3</span>] <span class="op">-</span><span class="st"> </span>quartiles_a[<span class="dv">1</span>])</a>
<a class="sourceLine" id="cb30-3" data-line-number="3">quartile_skew_a</a></code></pre></div>
<pre><code>## [1] -0.4285714</code></pre>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb32-1" data-line-number="1">quartiles_b &lt;-<span class="st"> </span><span class="kw">quantile</span>(b, <span class="dt">prob =</span> <span class="kw">c</span>(<span class="fl">0.25</span>, <span class="fl">0.50</span>, <span class="fl">0.75</span>), <span class="dt">type =</span> <span class="dv">2</span>, <span class="dt">names =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb32-2" data-line-number="2">quartile_skew_b &lt;-<span class="st"> </span>((quartiles_b[<span class="dv">3</span>] <span class="op">-</span><span class="st"> </span>quartiles_b[<span class="dv">2</span>]) <span class="op">-</span><span class="st"> </span>(quartiles_b[<span class="dv">2</span>] <span class="op">-</span><span class="st"> </span>quartiles_b[<span class="dv">1</span>])) <span class="op">/</span><span class="st"> </span>(quartiles_b[<span class="dv">3</span>] <span class="op">-</span><span class="st"> </span>quartiles_b[<span class="dv">1</span>])</a>
<a class="sourceLine" id="cb32-3" data-line-number="3">quartile_skew_b</a></code></pre></div>
<pre><code>## [1] -0.4285714</code></pre>
</div>
</div>
<div id="other-resistant-measures" class="section level2">
<h2><span class="header-section-number">1.5</span> Other Resistant Measures</h2>
<p>Other percentiles may be used to produce a series of resistant measures of location, spread and skewness. For example, the 10 percent trimmed mean can be coupled with the range between the 10th and 90th percentiles as a measure of spread, and a corresponding measure of skewness:
<span class="math display" id="eq:1-12">\[\begin{equation}
qs_{.10} = \frac{(P_{.90}-P_{.50})-(P_{.50}-P_{.10})}{P_{.90}-P_{.10}}
\tag{1.12}
\end{equation}\]</span></p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb34-1" data-line-number="1">quartiles_x &lt;-<span class="st"> </span><span class="kw">quantile</span>(x, <span class="dt">prob =</span> <span class="kw">c</span>(<span class="fl">0.10</span>, <span class="fl">0.50</span>, <span class="fl">0.90</span>), <span class="dt">type =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb34-2" data-line-number="2"><span class="co"># There are 9 different types you can specify. Type 2 seems to be the method used herein.</span></a>
<a class="sourceLine" id="cb34-3" data-line-number="3">quartile_skew_<span class="dv">10</span>_x &lt;-<span class="st"> </span>((quartiles_x[<span class="dv">3</span>] <span class="op">-</span><span class="st"> </span>quartiles_x[<span class="dv">2</span>]) <span class="op">-</span><span class="st"> </span>(quartiles_x[<span class="dv">2</span>] <span class="op">-</span><span class="st"> </span>quartiles_x[<span class="dv">1</span>])) <span class="op">/</span><span class="st"> </span>(quartiles_x[<span class="dv">3</span>] <span class="op">-</span><span class="st"> </span>quartiles_x[<span class="dv">1</span>])</a></code></pre></div>
<p>to produce a consistent series of resistant statistics. Geologists have used the 16th and 84th percentiles for many years to compute a similar series of robust measures of the distributions of sediment particles (<span class="citation">Inman (<a href="#ref-inman_measures_1952">1952</a>)</span>). However, measures based on quartiles have become generally standard, and other measures should be clearly defined prior to their use. The median, IQR, and quartile skew can be easily summarized graphically using a boxplot (see Chapter <a href="ch2.html#ch2">2</a>) and are familiar to most data analysts.</p>
</div>
<div id="outliers" class="section level2">
<h2><span class="header-section-number">1.6</span> Outliers</h2>
<p>Outliers, observations whose values are quite different than others in the data set, often cause concern or alarm. They should not. They are often dealt with by throwing them away prior to describing data, or prior to some of the hypothesis test procedures of later chapters. Again, they should not. Outliers may be the most important points in the data set, and should be investigated further.</p>
<p>It is said that data on the Antarctic ozone “hole”, an area of unusually low ozone concentrations, had been collected for approximately 10 years prior to its actual discovery. However, the automatic data checking routines during data processing included instructions on deleting “outliers”. The definition of outliers was based on ozone concentrations found at mid-latitudes. Thus all of this unusual data was never seen or studied for some time. If outliers are deleted, the risk is taken of seeing only what is expected to be seen.</p>
<p>Outliers can have one of three causes:</p>
<ol style="list-style-type: decimal">
<li>a measurement or recording error.</li>
<li>an observation from a population not similar to that of most of the data, such as a flood caused by a dam break rather than by precipitation.</li>
<li>a rare event from a single population that is quite skewed.</li>
</ol>
<p>The graphical methods of the Chapter <a href="ch2.html#ch2">2</a> are very helpful in identifying outliers. Whenever outliers occur, first verify that no copying, decimal point, or other obvious error has been made. If not, it may not be possible to determine if the point is a valid one. The effort put into verification, such as re-running the sample in the laboratory, will depend on the benefit gained versus the cost of verification. Past events may not be able to be duplicated. If no error can be detected and corrected, <strong>outliers should not be discarded based solely on the fact that they appear unusual</strong>. Outliers are often discarded in order to make the data nicely fit a preconceived theoretical distribution such as the normal. There is no reason to suppose that they should! The entire data set may arise from a skewed distribution, and taking logarithms or some other transformation may produce quite symmetrical data. Even if no transformation achieves symmetry, outliers need not be discarded. Rather than eliminating actual (and possibly very important) data in order to use analysis procedures requiring symmetry or normality, procedures which are resistant to outliers should instead be employed. If computing a mean appears of little value because of an outlier, the median has been shown to be a more appropriate measure of location for skewed data. If performing a t-test (described later) appears invalidated because of the non-normality of the data set, use a rank-sum test instead.</p>
<p>In short, let the data guide which analysis procedures are employed, rather than altering the data in order to use some procedure having requirements too restrictive for the situation at hand.</p>
</div>
<div id="transformations" class="section level2">
<h2><span class="header-section-number">1.7</span> Transformations</h2>
<p>Transformations are used for three purposes:</p>
<ol style="list-style-type: decimal">
<li>to make data more symmetric,</li>
<li>to make data more linear, and</li>
<li>to make data more constant in variance.</li>
</ol>
<p>Some water resources scientists fear that by transforming data, results are derived which fit preconceived ideas. Therefore, transformations are methods to ‘see what you want to see’ about the data. But in reality, serious problems can occur when procedures assuming symmetry, linearity, or homoscedasticity (constant variance) are used on data which do not possess these required characteristics. Transformations can produce these characteristics, and thus the use of transformed variables meets an objective. Employment of a transformation is not merely an arbitrary choice.</p>
<p>One unit of measurement is no more valid a priori than any other. For example, the negative logarithm of hydrogen ion concentration, pH, is as valid a measurement system as hydrogen ion concentration itself. Transformations like the square root of depth to water at a well, or cube root of precipitation volume, should bear no more stigma than does pH. These measurement scales may be more appropriate for data analysis than are the original units. <span class="citation">Hoaglin (<a href="#ref-hoaglin_transformations_1988">1988</a>)</span> has written an excellent article on hidden transformations, consistently taken for granted, which are in common use by everyone. Octaves in music are a logarithmic transform of frequency. Each time a piano is played a logarithmic transform is employed! Similarly, the Richter scale for earthquakes, miles per gallon for gasoline consumption, f-stops for camera exposures, etc. all employ transformations. In the science of data analysis, the decision of which measurement scale to use should be determined by the data, not by preconceived criteria. The objectives for use of transformations are those of symmetry, linearity and homoscedasticity. In addition, the use of many resistant techniques such as percentiles and nonparametric test procedures (to be discussed later) are invariant to measurement scale. The results of a rank-sum test, the nonparametric equivalent of a t-test, will be exactly the same whether the original units or logarithms of those units are employed.</p>
<div id="the-ladder-of-powers" class="section level3">
<h3><span class="header-section-number">1.7.1</span> The Ladder of Powers</h3>
<p>In order to make an asymmetric distribution become more symmetric, the data can be transformed or re-expressed into new units. These new units alter the distances between observations on a line plot. The effect is to either expand or contract the distances to extreme observations on one side of the median, making it look more like the other side. The most commonly-used transformation in water resources is the logarithm. Logs of water discharge, hydraulic conductivity, or concentration are often taken before statistical analyses are performed.</p>
<p>Transformations usually involve power functions of the form <span class="math inline">\(y = x^{\mathbf{θ}}\)</span>, where x is the untransformed data, y the transformed data, and θ the power exponent. In figure <a href="ch1.html#fig:fig-1-5">1.6</a> the values of θ are listed in the “ladder of powers” (<span class="citation">Velleman and Hoaglin (<a href="#ref-velleman_applications_1981">1981</a>)</span>), a useful structure for determining a proper value of <strong>θ</strong>.</p>
As can be seen from the ladder of powers, any transformations with θ less than 1 may be used to make right-skewed data more symmetric. Constructing a boxplot or Q-Q plot (see Chapter <a href="ch2.html#ch2">2</a>) of the transformed data will indicate whether the transformation was appropriate. Should a logarithmic transformation overcompensate for right skewness and produce a slightly leftskewed distribution, a ‘milder’ transformation with θ closer to 1, such as a square-root or cuberoot transformation, should be employed instead. Transformations with θ &gt; 1 will aid in making left-skewed data more symmetric.
<div class="figure" style="text-align: center"><span id="fig:fig-1-5"></span>
<img src="figures/1_5.png" alt="&quot;LADDER OF POWERS&quot; (modified from @velleman_applications_1981)" width="456" />
<p class="caption">
Figure 1.6: “LADDER OF POWERS” (modified from <span class="citation">Velleman and Hoaglin (<a href="#ref-velleman_applications_1981">1981</a>)</span>)
</p>
</div>
<p>However, the tendency to search for the ‘best’ transformation should be avoided. For example, when dealing with several similar data sets, it is probably better to find one transformation which works reasonably well for all, rather than using slightly different ones for each. It must be remembered that each data set is a sample from a larger population, and another sample from the same population will likely indicate a slightly different ‘best’ transformation. Determination of ‘best’ in great precision is an approach that is rarely worth the effort.</p>
</div>
</div>
<div id="exercises" class="section level2 unnumbered">
<h2>Exercises</h2>
<div id="section" class="section level3 unnumbered">
<h3>1.1</h3>
<p>Yields in wells penetrating rock units without fractures were measured by <span class="citation">Wright (<a href="#ref-wright_effects_1985">1985</a>)</span>, and are given below. Calculate the</p>
<ol style="list-style-type: lower-alpha">
<li>mean</li>
<li>trimmed mean</li>
<li>geometric mean</li>
<li>median</li>
<li>compare these estimates of location. Why do they differ?</li>
</ol>
</div>
<div id="section-1" class="section level3 unnumbered">
<h3>1.2</h3>
<p>For the well yield data of exercise 1.1, calculate the</p>
<ol style="list-style-type: lower-alpha">
<li>standard deviation</li>
<li>interquartile range</li>
<li>MAD</li>
<li>skew and quartile skew.</li>
</ol>
<p>Discuss the differences between a through c.</p>
</div>
<div id="section-2" class="section level3 unnumbered">
<h3>1.3</h3>
<p>Ammonia plus organic nitrogen (in mg/L) was measured in samples of precipitation by <span class="citation">Oltmann and Shulters (<a href="#ref-oltmann_rainfall_1989">1989</a>)</span>. Some of their data are presented below. Compute summary statistics for these data. Which observation might be considered an outlier?<br />
How should this value affect the choice of summary statistics used</p>
<ol style="list-style-type: lower-alpha">
<li>to compute the mass of nitrogen falling per square mile.</li>
<li>to compute a “typical” concentration and variability for these data?</li>
</ol>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-hoaglin_transformations_1988">
<p>Hoaglin, David C. 1988. “Transformations in Everyday Experience.” <em>Chance</em> 1 (4): 40–45.</p>
</div>
<div id="ref-inman_measures_1952">
<p>Inman, Douglas Lamar. 1952. “Measures for Describing the Size Distribution of Sediments.” <em>Journal of Sedimentary Research</em> 22 (3). SEPM Society for Sedimentary Geology: 125–45.</p>
</div>
<div id="ref-kenney_mathematics_1954">
<p>Kenney, John Francis, and Ernest Sydney Keeping. 1954. <em>Mathematics of Statistics: Part One</em>. D. van Nostrand.</p>
</div>
<div id="ref-oltmann_rainfall_1989">
<p>Oltmann, Richard N, and Michael V Shulters. 1989. “Rainfall and Runoff Quantity and Quality Characteristics of Four Urban Land-Use Catchments in Fresno, California, October 1981 to April 1983.” USGPO; For sale by the Books; Open-File Reports Section, US Geological ….</p>
</div>
<div id="ref-velleman_applications_1981">
<p>Velleman, PF, and DC Hoaglin. 1981. <em>Applications, Basics, and Computing of Exploratory Data Analysis, Wadsworth</em>. Duxbury Press, Boston, MA.</p>
</div>
<div id="ref-wright_effects_1985">
<p>Wright, Winfield G. 1985. “Effects of Fracturing on Well Yields in the Coalfield Areas of Wise and Dickenson Counties, Southwestern Virginia.” US Geological Survey,</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ch2.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Statistical-Methods-in-Water-Resources.pdf", "Statistical-Methods-in-Water-Resources.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
